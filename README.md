# EVOO â€” Evolutionary Operations Optimizer

<div align="center">

```
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                                       â•‘
    â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                 â•‘
    â•‘   â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—                                â•‘
    â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘                                â•‘
    â•‘   â–ˆâ–ˆâ•”â•â•â•  â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘                                â•‘
    â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•                                â•‘
    â•‘   â•šâ•â•â•â•â•â•â•  â•šâ•â•â•â•   â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•                                 â•‘
    â•‘                                                                       â•‘
    â•‘   Evolutionary Operations Optimizer                                   â•‘
    â•‘   An Autonomous AI SRE Agent with Reward-Based Learning              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Version 2.0.0** | Built with [scale-agentex](../../agentex) and OpenAI SDK ADK

</div>

---

## ğŸ¯ Overview

EVOO is an **autonomous AI agent** that behaves like a real Site Reliability Engineer (SRE). It continuously improves its incident remediation strategy over time using:

- **Feedback** from remediation outcomes
- **Memory** of past experiences
- **Strategy optimization** via reward-based learning

Unlike traditional rule-based incident response systems, EVOO **learns from its mistakes** and **gets better over time**.

---

## ğŸ§  Core Capabilities

| Capability | Description |
|------------|-------------|
| **Incident Detection** | Detects production incidents in a simulated system |
| **Strategy Selection** | Uses epsilon-greedy exploration with experience-based exploitation |
| **Tool Execution** | Calls remediation tools (restart, scale, rollback, etc.) |
| **Outcome Measurement** | Collects before/after metrics to measure effectiveness |
| **Reward Scoring** | Calculates numeric reward + LLM judge evaluation |
| **Memory Storage** | Persists experience tuples for future reference |
| **Learning Loop** | Improves decision-making based on accumulated experience |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         EVOO Learning Loop                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ INCIDENT         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Simulated Production System
    â”‚ DETECTION        â”‚             generates random incidents
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PLANNER AGENT    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Memory Retrieval
    â”‚ (LLM-powered)    â”‚             + Epsilon-Greedy Selection
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ EXECUTOR AGENT   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Remediation Tools
    â”‚                  â”‚             (restart, scale, rollback...)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ EVALUATOR AGENT  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Reward Function
    â”‚ (LLM Judge)      â”‚             + Qualitative Assessment
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ STRATEGY MANAGER â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Update Rankings
    â”‚                  â”‚             + Store Experience
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Loop back to INCIDENT DETECTION
```

---

## ğŸ“Š Incident Types Supported

| Incident Type | Typical Metrics | Best Strategies |
|---------------|-----------------|-----------------|
| `service_crash` | High error rate, low availability | restart_service, rollback_deployment |
| `high_latency` | P99 > 2000ms, elevated CPU | scale_horizontal, rebalance_load |
| `cpu_spike` | CPU > 85%, request throttling | scale_vertical, scale_horizontal |
| `memory_leak` | Memory > 88%, OOMKiller risk | restart_service, clear_cache |
| `network_degradation` | Packet loss, latency spikes | rebalance_load, scale_horizontal |
| `timeout_misconfiguration` | Cascading timeouts | change_timeout, rollback_deployment |

---

## ğŸ”§ Available Remediation Tools

### Core Tools

| Tool | Description | Parameters |
|------|-------------|------------|
| `restart_service()` | Graceful service restart | service_name |
| `scale_horizontal()` | Add/remove instances | target_instances |
| `scale_vertical()` | Adjust CPU/memory limits | target_cpu, target_memory |
| `change_timeout()` | Update timeout configuration | new_timeout_ms |
| `rollback_deployment()` | Revert to previous version | target_version |
| `clear_cache()` | Free memory by clearing caches | cache_type |
| `rebalance_load()` | Redistribute traffic | algorithm |

### Advanced Tools

| Tool | Description |
|------|-------------|
| `analyze_logs()` | Identify root cause patterns in logs |
| `predict_incident_type()` | Heuristic prediction from metrics |
| `query_metrics()` | Query observability stack |
| `apply_previous_successful_strategy()` | Retrieve best historical strategy |

---

## ğŸ“ˆ Reward Function

The reward function scores each remediation action:

```python
reward = 0.0

# Positive factors
if service_restored:
    reward += 100.0
reward += latency_improvement * 0.1
reward += availability_improvement * 30.0
reward += cpu_improvement * 0.05

# Negative factors
reward -= recovery_time_seconds * 0.5
reward -= infrastructure_cost * 0.2
reward -= error_rate_after * 50.0
if unnecessary_scaling:
    reward -= 10.0
```

Additionally, an **LLM-based judge** provides qualitative evaluation:

- Score: 0-10
- Verdict: excellent | good | adequate | poor | failed
- Analysis: 2-sentence explanation
- Better strategy suggestion

---

## ğŸ§¬ Learning Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚   Early Runs (exploration phase):                                       â”‚
â”‚   â”œâ”€ Agent tries random strategies                                      â”‚
â”‚   â”œâ”€ Recovery time: HIGH                                                â”‚
â”‚   â”œâ”€ Reward: LOW                                                        â”‚
â”‚   â””â”€ Building experience database                                       â”‚
â”‚                                                                         â”‚
â”‚   Later Runs (exploitation phase):                                      â”‚
â”‚   â”œâ”€ Agent selects optimal strategies based on history                  â”‚
â”‚   â”œâ”€ Recovery time: LOW                                                 â”‚
â”‚   â”œâ”€ Reward: HIGH                                                       â”‚
â”‚   â””â”€ Continuous improvement measurable                                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Epsilon-Greedy Strategy Selection

- With probability Îµ (default 0.2): **EXPLORE** new strategies
- With probability 1-Îµ: **EXPLOIT** best known strategy

---

## ğŸ’¾ Memory Model

Experiences are stored as tuples:

```json
{
  "id": "abc12345",
  "incident_type": "high_latency",
  "metrics_before": {
    "latency_ms": 5420,
    "cpu_percent": 72.3,
    "availability": 0.68
  },
  "strategy_used": "scale_horizontal",
  "tools_called": ["query_metrics_tool_activity", "scale_horizontal_activity"],
  "metrics_after": {
    "latency_ms": 142,
    "cpu_percent": 31.2,
    "availability": 0.998
  },
  "recovery_time_seconds": 24.3,
  "reward": 85.7,
  "llm_evaluation": "Excellent recovery. Horizontal scaling effectively addressed...",
  "success": true,
  "timestamp": "2026-02-14T08:15:00Z",
  "run_index": 42
}
```

---

## ğŸš€ Quick Start

### Standalone Mode (No Platform Required)

```bash
cd agents/evoo

# Install dependencies
pip install -e .

# Run the learning loop (30 cycles)
python run_evoo_standalone.py --runs 30 --explore 0.2

# With OpenAI LLM judge
python run_evoo_standalone.py --runs 50 --openai-key sk-your-key
```

### With AgentEx Platform

```bash
# Start the Temporal worker
python project/run_worker.py

# The agent will be available at the configured endpoint
# Create a task via the AgentEx API to start the learning loop
```

---

## âš™ï¸ Configuration

| Environment Variable | Default | Description |
|---------------------|---------|-------------|
| `MAX_LEARNING_RUNS` | 50 | Number of learning cycles |
| `EXPLORATION_RATE` | 0.2 | Epsilon for exploration |
| `OPENAI_API_KEY` | - | For LLM judge (optional) |
| `OPENAI_MODEL` | gpt-4o-mini | LLM model for reasoning |
| `MEMORY_FILE_PATH` | /tmp/evoo_memory.json | Experience storage |
| `STRATEGY_FILE_PATH` | /tmp/evoo_strategies.json | Strategy rankings |

---

## ğŸ“Š Observability

EVOO provides comprehensive observability:

### Logged Events
- All agent decisions
- Tool call inputs/outputs
- Reward calculations
- Strategy ranking updates

### Metrics Tracked
- Average recovery time per incident type
- Reward over time (with trend)
- Strategy success rate
- Learning improvement (early vs late runs)

### Milestone Reports
Every 10 runs, EVOO emits a detailed summary:
- Reward metrics (average, best)
- Recovery time metrics
- Most used strategies
- Learning trend analysis

---

## ğŸ§ª Example Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   EVOO â€” Evolutionary Operations Optimizer (Standalone Mode)    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Runs: 30     Exploration: 0.2    OpenAI: YES                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Run   1/30
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  INCIDENT : service_crash
  STRATEGY : restart_service [EXPLORE]
  RESULT   : âœ“ RESTORED | Recovery: 18.2s
  REWARD   : +72.45
  LLM JUDGE: GOOD
  METRICS  : Latency 8234ms â†’ 145ms (â†“8089ms) | Availability 12% â†’ 99.8%

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Run  30/30
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  INCIDENT : cpu_spike
  STRATEGY : scale_vertical [EXPLOIT]
  RESULT   : âœ“ RESTORED | Recovery: 12.1s
  REWARD   : +89.23
  LLM JUDGE: EXCELLENT

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  EVOO LEARNING COMPLETE â€” FINAL REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Metric                              Value
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total Runs                             30
  Average Reward (all)                 68.45
  Average Reward (first 5)             52.12
  Average Reward (last 5)              84.78
  Net Improvement                     +32.66 (IMPROVED âœ“)
  Best Reward                          94.21
  Avg Recovery Time                    22.3s
  Best Recovery Time                    8.4s

  Strategy Rankings Learned:
  service_crash          restart_service(78.2) > rollback_deployment(71.5)
  high_latency           scale_horizontal(82.1) > rebalance_load(68.9)
  cpu_spike              scale_vertical(85.4) > scale_horizontal(79.2)
```

---

## ğŸ“ Project Structure

```
agents/evoo/
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ acp.py                    # ACP server configuration
â”‚   â”œâ”€â”€ constants.py              # Configuration constants
â”‚   â”œâ”€â”€ run_worker.py             # Temporal worker entry
â”‚   â”œâ”€â”€ workflow.py               # Main workflow orchestration
â”‚   â”‚
â”‚   â”œâ”€â”€ activities/               # Temporal activities
â”‚   â”‚   â”œâ”€â”€ simulation_activities.py   # Production system simulator
â”‚   â”‚   â”œâ”€â”€ remediation_activities.py  # Tool implementations
â”‚   â”‚   â”œâ”€â”€ memory_activities.py       # Experience persistence
â”‚   â”‚   â”œâ”€â”€ reward_activities.py       # Reward function + LLM judge
â”‚   â”‚   â””â”€â”€ strategy_activities.py     # Epsilon-greedy selection
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # Data models
â”‚   â”‚   â”œâ”€â”€ incident.py           # Incident, SystemMetrics
â”‚   â”‚   â””â”€â”€ experience.py         # Experience, StrategyRecord
â”‚   â”‚
â”‚   â”œâ”€â”€ state_machines/           # State machine definition
â”‚   â”‚   â””â”€â”€ evoo_agent.py         # EVOOState, EVOOData
â”‚   â”‚
â”‚   â””â”€â”€ workflows/                # State workflows
â”‚       â”œâ”€â”€ idle/
â”‚       â”‚   â””â”€â”€ waiting_for_incident.py
â”‚       â”œâ”€â”€ planning/
â”‚       â”‚   â””â”€â”€ planning_remediation.py    # Planner Agent
â”‚       â”œâ”€â”€ execution/
â”‚       â”‚   â””â”€â”€ executing_remediation.py   # Executor Agent
â”‚       â”œâ”€â”€ evaluation/
â”‚       â”‚   â””â”€â”€ evaluating_outcome.py      # Evaluator Agent
â”‚       â”œâ”€â”€ learning/
â”‚       â”‚   â””â”€â”€ updating_strategy.py       # Strategy Manager
â”‚       â””â”€â”€ terminal_states.py
â”‚
â”œâ”€â”€ run_evoo_standalone.py        # Standalone demo script
â”œâ”€â”€ manifest.yaml                 # Agent manifest
â”œâ”€â”€ pyproject.toml                # Python dependencies
â”œâ”€â”€ Dockerfile                    # Container build
â””â”€â”€ README.md                     # This file
```

---

## ğŸ”¬ Technical Details

### OpenAI SDK ADK Integration

EVOO uses OpenAI SDK ADK for:

1. **Planner reasoning**: Explains why a strategy was selected
2. **Evaluator judgment**: Qualitative assessment of remediation effectiveness
3. **Strategy suggestions**: Recommends better alternatives when appropriate

### scale-agentex Framework

Built on scale-agentex patterns:
- State machine-based workflow orchestration
- Activity-based tool execution
- Persistent state across workflow steps
- Signal handling for runtime control

---

## ğŸ“ Success Criteria

EVOO demonstrates success when:

- [x] Agent improves remediation performance over time
- [x] Agent selects best strategies based on experience
- [x] Reward improves measurably over runs
- [x] Recovery time decreases over runs
- [x] Agent demonstrates autonomous learning

---

## ğŸ“„ License

MIT License â€” See [LICENSE](../../LICENSE)

---

<div align="center">

**Built with â¤ï¸ for autonomous SRE operations**

*EVOO learns so you don't have to be on-call at 3 AM*

</div>
